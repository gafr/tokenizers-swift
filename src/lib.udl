namespace tokenizers {
};

[Error]
enum TokenizersError {
  "Tokenizer",
  "ValueError",
  "Exception",
};

interface RustTokenizer {
  [Name=from_pretrained, Throws=TokenizersError]
  constructor(
    [ByRef] string identifier,
    string revision,
    string? auth_token);

  [Throws=TokenizersError]
  RustEncoding encode([ByRef] string input, boolean add_special_tokens);
};

interface RustEncoding {
  sequence<string> get_tokens();
};

// Models
interface RustBPE {
  [Throws=TokenizersError]
  constructor(
    record<string, u32>? vocab,
    sequence<sequence<string>>? merges,
    string? vocab_file,
    string? merges_file,
    u32? cache_capacity,
    float? dropout,
    string? unk_token,
    string? continuing_subword_prefix,
    string? end_of_word_suffix,
    boolean? fuse_unk
  );

  string? get_unk_token();
};